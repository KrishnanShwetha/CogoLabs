{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AI6kCjUdadG"
      },
      "source": [
        "\n",
        "\n",
        "Translating data exploration of Cogo Labs intuition into a machine learning model to predict email open rates for new customers based on their browsing behaviour.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_jWf_sDdxk6"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Lets start by importing the packages we'll need and mounting our Google Drive as before. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZNxLcICQuclV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0740ce47-4064-4542-c3e5-3bba0184db5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9Xg2nxHd-b7"
      },
      "source": [
        "We'll use the `read_csv` function to read the dataset, be sure to take a look at the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html). There are mamy optional arguments you may find useful when working on your project dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xqONUClOu9vo"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/MLBA/cogo-all.tsv', delimiter='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OB4IU45eY4T"
      },
      "source": [
        "We have to split the data into a training and testing set. \n",
        "\n",
        "We create a new column called `train` which is `True` if the instance should be included in the training by using the numpy random number generator. Once we have this column, we can filter on it to create two new dataframes. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iqYd7CNywwVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06891198-aebb-4368-cb1f-f3a9ef753b3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(230760, 18) (57538, 18)\n"
          ]
        }
      ],
      "source": [
        "df['train'] = np.random.rand(len(df)) < 0.8\n",
        "\n",
        "df_train = df[df.train == True]\n",
        "df_test = df[df.train == False]\n",
        "\n",
        "print(df_train.shape, df_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg5CwMumfQjJ"
      },
      "source": [
        "We can refresh our memories of what goes on in the dataset by looking at the column names. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "E3SCMbcXAWTX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "966b933c-4270-43f2-f7c7-4d4ab26f5d60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['state', 'user_id', 'browser1', 'browser2', 'browser3', 'device_type1',\n",
              "       'device_type2', 'device_type3', 'device_type4', 'activity_observations',\n",
              "       'activity_days', 'activity_recency', 'activity_locations',\n",
              "       'activity_ids', 'age', 'gender', 'p_open', 'train'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s5oNkZ-fHTs"
      },
      "source": [
        "## Training a linear regression model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou8rI9j0f5f5"
      },
      "source": [
        "Let's start by setting up a very simple model that only cares about which browser a user uses. We will create a list, `predictors1` to hold ne column names of the predictors we want to include in our model to make indexing easier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MHC31vFIgj84"
      },
      "outputs": [],
      "source": [
        "predictors = ['browser1', 'browser2', 'browser3']\n",
        "X1_train = df_train[predictors]\n",
        "X1_test = df_test[predictors]\n",
        "y_train = df_train['p_open']\n",
        "y_test = df_test['p_open']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjwF4ts1i1uW",
        "outputId": "dc9009a9-e53c-4ff2-c38b-2adfbbb9735f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         0.000000\n",
              "1         0.018100\n",
              "2         0.035912\n",
              "5         0.070740\n",
              "8         0.006849\n",
              "            ...   \n",
              "288292    0.004878\n",
              "288293    0.002083\n",
              "288294    0.337838\n",
              "288296    0.008000\n",
              "288297    0.009009\n",
              "Name: p_open, Length: 230396, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHaZtj6cgrWi"
      },
      "source": [
        "Now we can follow the same four steps as always. First, choose a model class, instantiante the model and set hyperparameter values, then fit to your data. Remember we can access model attributes, in this case the coefficients and intercepts term.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZKv-j8ctxqMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3945839-d2d4-4a0f-fca3-3128003913ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.01604796, 0.0061872 , 0.04667057]), 0.0703354127738299)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression # 1. choose model class\n",
        "\n",
        "model = LinearRegression()                         # 2. instantiate model\n",
        "model = model.fit(X1_train, y_train)               # 3. fit model to data\n",
        "\n",
        "model.coef_, model.intercept_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzwefjGYhlyz"
      },
      "source": [
        "Finally, we make predictions on the training and test set and evaluate the mean squared error. Of course, there are automated functions for this, but let's do it manually so that we can make sure we understand how it works. \n",
        "\n",
        "First we predict on the training data:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_fit = model.predict(X1_train)                  # 4a. predict on training data\n",
        "\n",
        "mse_train = np.mean( (y_train - y_train_fit)**2 )   # Evaluate\n",
        "print(np.sqrt(mse_train), mse_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD6eij4SlezX",
        "outputId": "cfb49bce-29f7-415e-e005-9bc18f4fc18e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.16845445616029722 0.0283769038002615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0czfTAwGs5Wm"
      },
      "source": [
        "Then on the testing data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5H6Qo8jNtmN1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5291eb25-3665-475d-a2a3-558cd99db364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.17102062847620725 0.02924805536439691\n"
          ]
        }
      ],
      "source": [
        "y_test_fit = model.predict(X1_test)                  # 4a. predict on testing data\n",
        "\n",
        "mse_test = np.mean( (y_test - y_test_fit)**2 )   # Evaluate\n",
        "print(np.sqrt(mse_test), mse_test) # root mean squared error and mean squared error "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MSE train = 0.028518754475621244\n",
        "# MSE test = 0.02867812563757728"
      ],
      "metadata": {
        "id": "QQJi4Y1il47O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si6Ov0yps8Rl"
      },
      "source": [
        "In this case our MSE is pretty similar, so it's unlikely we overfit. Is this a \"good\" MSE? We don't really know, but we can say that our open-rate predictions are, on average, off by about 17\\%. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p2_5bRteL72"
      },
      "source": [
        "## KNN regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGJTMVlLeL73"
      },
      "source": [
        "Use the same steps as above to train a KNN regression, and compute MSE train and MSE test. How do they compare to linear regression?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pQl_3Jm9eL74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6280b27a-50e4-4621-9cbb-f59752c1cf21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.18083482061022202 0.03270123234513118\n",
            "0.18304417639399126 0.033505170511754584\n"
          ]
        }
      ],
      "source": [
        "# Using the same process as above perform a KNN regression, and compute MSE train/test\n",
        "from sklearn import neighbors                           # 1. choose model class\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "n_neighbors = 5\n",
        "model = neighbors.KNeighborsRegressor(n_neighbors)      # 2. instantiate model\n",
        "model.fit(X1_train, y_train)                            # 3. fit model to data\n",
        "\n",
        "y_train_fit = model.predict(X1_train)                   # 4a. predict on training data\n",
        "\n",
        "mse_train = np.mean( (y_train - y_train_fit)**2 )\n",
        "print(np.sqrt(mse_train), mse_train)\n",
        "\n",
        "y_test_fit = model.predict(X1_test)                     # 4b. predict on test data\n",
        "mse_test = np.mean( (y_test - y_test_fit)**2 )\n",
        "print(np.sqrt(mse_test), mse_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCl_soyWIyqY"
      },
      "source": [
        "## Categorical predictors and polynomial basis functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oWFKx6gi-_7"
      },
      "source": [
        "Up to now we have only used numerical columns. Let's include some categorical predictors like `gender`  and create polynomial features for the `activity_days` feature. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0QB5LKcn7DIh"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# all predictors \n",
        "numerical_predictors = ['browser1', 'browser2', 'browser3'] # numerical\n",
        "categorical_predictors = ['gender'] # categorical\n",
        "poly_predictors = ['activity_days'] # polynomial features \n",
        "all_predictors = numerical_predictors + categorical_predictors + poly_predictors\n",
        "\n",
        "# list of the two transformation we want to do\n",
        "t = [('cat', OneHotEncoder(), categorical_predictors), \n",
        "     ('poly', PolynomialFeatures(2, include_bias=False), poly_predictors)]\n",
        "\n",
        "# instantiate columntransformer with our transforamtions t\n",
        "col_transform = ColumnTransformer(transformers=t, remainder='passthrough')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMNrf7pZNILE"
      },
      "source": [
        "Now we can apply the transformation to our training and testing sets. Notice that we have 7 columns after transformation: 3 for the browsers; 2 for the gender one-hot encoding and 2 for `activity_days` and `activity_days`$^2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ORi-uzoK-SVA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3728909e-af75-4e54-a802-bc5d398d4419"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(230760, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "xt_train = col_transform.fit_transform(df_train[all_predictors])\n",
        "xt_test = col_transform.fit_transform(df_test[all_predictors])\n",
        "xt_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Pr3LCkvNzXE"
      },
      "source": [
        "We can choose and fit a model as before on this new data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ODoxuD3IN5qO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f198d51-a86a-4fd8-8f54-f12c7dae3c7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.029028577145774018\n"
          ]
        }
      ],
      "source": [
        "model = LinearRegression(fit_intercept=True)\n",
        "model.fit(xt_train, y_train)\n",
        "yhat_test = model.predict(xt_test)\n",
        "mse_test = np.mean( (y_test - yhat_test)**2)\n",
        "print(mse_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10 | packaged by conda-forge | (default, May 11 2021, 06:25:23) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "8ddc49676faceb3e8cb567e61f8f552440a95f15ba10e7733a70b03786a0351b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}